{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re \n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "import os \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation,Embedding, Flatten,Bidirectional,MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean unwanted thing from dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>But instead of returning to heaven , Annie dec...</td>\n",
       "      <td>But instead of returning to Heaven , Chris cho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In 2016 , Bacardi announced new branding and p...</td>\n",
       "      <td>In 2016 , Bacardi announced new branding and p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kweku Baako Jnr had four children . One of the...</td>\n",
       "      <td>Baako had four children , one of whom was Kwek...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As with the Navy , the Army has a single-track...</td>\n",
       "      <td>Like the army , the Navy has a single-track sy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sissi units have fewer crew served weapons and...</td>\n",
       "      <td>Sissi units have more weapons served by the cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>15995</td>\n",
       "      <td>On July 21st , 1919 , the army was renamed int...</td>\n",
       "      <td>On July 21 , 1919 , the army was renamed the C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>15996</td>\n",
       "      <td>In 2012 , the championships were held in Dunak...</td>\n",
       "      <td>In 2012 , the championships were held in Italy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>15997</td>\n",
       "      <td>At least 3 inserts were printed , but none of ...</td>\n",
       "      <td>At least 3 supplements were printed , but none...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>15998</td>\n",
       "      <td>The builders of Waimate North were also Willia...</td>\n",
       "      <td>The builders of St. James were also William Wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>15999</td>\n",
       "      <td>It was destroyed and finally rebuilt during th...</td>\n",
       "      <td>It was destroyed and finally rebuilt during th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                          Sentence1  \\\n",
       "0          0  But instead of returning to heaven , Annie dec...   \n",
       "1          1  In 2016 , Bacardi announced new branding and p...   \n",
       "2          2  Kweku Baako Jnr had four children . One of the...   \n",
       "3          3  As with the Navy , the Army has a single-track...   \n",
       "4          4  Sissi units have fewer crew served weapons and...   \n",
       "...      ...                                                ...   \n",
       "15995  15995  On July 21st , 1919 , the army was renamed int...   \n",
       "15996  15996  In 2012 , the championships were held in Dunak...   \n",
       "15997  15997  At least 3 inserts were printed , but none of ...   \n",
       "15998  15998  The builders of Waimate North were also Willia...   \n",
       "15999  15999  It was destroyed and finally rebuilt during th...   \n",
       "\n",
       "                                               Sentence2  Class  \n",
       "0      But instead of returning to Heaven , Chris cho...      0  \n",
       "1      In 2016 , Bacardi announced new branding and p...      0  \n",
       "2      Baako had four children , one of whom was Kwek...      0  \n",
       "3      Like the army , the Navy has a single-track sy...      0  \n",
       "4      Sissi units have more weapons served by the cr...      0  \n",
       "...                                                  ...    ...  \n",
       "15995  On July 21 , 1919 , the army was renamed the C...      1  \n",
       "15996  In 2012 , the championships were held in Italy...      0  \n",
       "15997  At least 3 supplements were printed , but none...      1  \n",
       "15998  The builders of St. James were also William Wi...      0  \n",
       "15999  It was destroyed and finally rebuilt during th...      0  \n",
       "\n",
       "[16000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=pd.read_csv('train1.csv')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Class', data=data,hue='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         16000 non-null  int64 \n",
      " 1   Sentence1  16000 non-null  object\n",
      " 2   Sentence2  16000 non-null  object\n",
      " 3   Class      16000 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 500.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Sentence1    0\n",
       "Sentence2    0\n",
       "Class        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>But instead of returning to heaven  Annie deci...</td>\n",
       "      <td>But instead of returning to Heaven  Chris choo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In 2016  Bacardi announced new branding and pl...</td>\n",
       "      <td>In 2016  Bacardi announced new branding and pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kweku Baako Jnr had four children  One of them...</td>\n",
       "      <td>Baako had four children  one of whom was Kweku...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As with the Navy  the Army has a singletrack s...</td>\n",
       "      <td>Like the army  the Navy has a singletrack syst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sissi units have fewer crew served weapons and...</td>\n",
       "      <td>Sissi units have more weapons served by the cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          Sentence1  \\\n",
       "0   0  But instead of returning to heaven  Annie deci...   \n",
       "1   1  In 2016  Bacardi announced new branding and pl...   \n",
       "2   2  Kweku Baako Jnr had four children  One of them...   \n",
       "3   3  As with the Navy  the Army has a singletrack s...   \n",
       "4   4  Sissi units have fewer crew served weapons and...   \n",
       "\n",
       "                                           Sentence2  Class  \n",
       "0  But instead of returning to Heaven  Chris choo...      0  \n",
       "1  In 2016  Bacardi announced new branding and pl...      0  \n",
       "2  Baako had four children  one of whom was Kweku...      0  \n",
       "3  Like the army  the Navy has a singletrack syst...      0  \n",
       "4  Sissi units have more weapons served by the cr...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation \n",
    "import string\n",
    "from string import punctuation\n",
    "def remove_punctuation(text):\n",
    "    no_punctuation=[words for words in text if words not in punctuation ]\n",
    "    words_wo_punct=''.join(no_punctuation)\n",
    "    return words_wo_punct\n",
    "data[\"Sentence1\"]=data[\"Sentence1\"].apply(lambda x:remove_punctuation(x))\n",
    "data[\"Sentence2\"]=data[\"Sentence2\"].apply(lambda x:remove_punctuation(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>instead return heaven anni decid join chris he...</td>\n",
       "      <td>instead return heaven chris choos join anni fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 bacardi announc new brand plan sell versi...</td>\n",
       "      <td>2016 bacardi announc new brand plan sell versi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>kweku baako jnr four children one baako journa...</td>\n",
       "      <td>baako four children one kweku baako jnr journa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>navi armi singletrack system offic navi commun...</td>\n",
       "      <td>like armi navi singletrack system offic navi c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sissi unit fewer crew serv weapon sniper rifl ...</td>\n",
       "      <td>sissi unit weapon serv crew fewer sniper rifl ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          Sentence1  \\\n",
       "0   0  instead return heaven anni decid join chris he...   \n",
       "1   1  2016 bacardi announc new brand plan sell versi...   \n",
       "2   2  kweku baako jnr four children one baako journa...   \n",
       "3   3  navi armi singletrack system offic navi commun...   \n",
       "4   4  sissi unit fewer crew serv weapon sniper rifl ...   \n",
       "\n",
       "                                           Sentence2  Class  \n",
       "0  instead return heaven chris choos join anni fo...      0  \n",
       "1  2016 bacardi announc new brand plan sell versi...      0  \n",
       "2  baako four children one kweku baako jnr journa...      0  \n",
       "3  like armi navi singletrack system offic navi c...      0  \n",
       "4  sissi unit weapon serv crew fewer sniper rifl ...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "stop_words=set(stopwords.words('english'))\n",
    "stemmer=SnowballStemmer('english')\n",
    "\n",
    "data['Sentence1'] = data['Sentence1'].apply(lambda x: ' '.join([stemmer.stem(word.lower()) for word in x.split() if word.lower() not in stop_words]))\n",
    "data['Sentence2'] = data['Sentence2'].apply(lambda x: ' '.join([stemmer.stem(word.lower()) for word in x.split() if word.lower() not in stop_words]))\n",
    "data.head()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Tokenization \\nfrom nltk.tokenize import word_tokenize\\ndata['Sentence1']=data['Sentence1'].apply(lambda x:' '.join(word_tokenize(x)))\\ndata['Sentence2']=data['Sentence2'].apply(lambda x:' '.join(word_tokenize(x)))\\ndata.head() \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Tokenization \n",
    "from nltk.tokenize import word_tokenize\n",
    "data['Sentence1']=data['Sentence1'].apply(lambda x:' '.join(word_tokenize(x)))\n",
    "data['Sentence2']=data['Sentence2'].apply(lambda x:' '.join(word_tokenize(x)))\n",
    "data.head() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sequential model \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test\n",
    "train_size=int(len(data)*0.8)\n",
    "train_data=data[:train_size]\n",
    "test_data=data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the text data \n",
    "tokenizer=Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data['Sentence1'])\n",
    "\n",
    "X_train=tokenizer.texts_to_sequences(train_data['Sentence1'])\n",
    "X_train=pad_sequences(X_train,maxlen=100)\n",
    "\n",
    "\n",
    "X_test=tokenizer.texts_to_sequences(test_data['Sentence1'])\n",
    "X_test=pad_sequences(X_test,maxlen=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 12s 31ms/step - loss: 0.6877 - accuracy: 0.5549 - val_loss: 0.6848 - val_accuracy: 0.5722\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.6478 - accuracy: 0.6216 - val_loss: 0.6995 - val_accuracy: 0.5359\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 6s 27ms/step - loss: 0.5722 - accuracy: 0.6973 - val_loss: 0.7567 - val_accuracy: 0.5297\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.5113 - accuracy: 0.7416 - val_loss: 0.8158 - val_accuracy: 0.5275\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.4573 - accuracy: 0.7766 - val_loss: 0.8846 - val_accuracy: 0.5259\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.3992 - accuracy: 0.8072 - val_loss: 1.0113 - val_accuracy: 0.5309\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3495 - accuracy: 0.8270 - val_loss: 1.2759 - val_accuracy: 0.5222\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.3045 - accuracy: 0.8480 - val_loss: 1.4580 - val_accuracy: 0.5213\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.2650 - accuracy: 0.8647 - val_loss: 1.8880 - val_accuracy: 0.5125\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.2351 - accuracy: 0.8724 - val_loss: 2.1983 - val_accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model architecture \n",
    "\n",
    "# Model creation \n",
    "with tf.device('/gpu:0'):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(5000, 128, input_length=100))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    model.fit(X_train, train_data['Class'], batch_size=64,epochs=10,validation_data=(X_test, test_data['Class']))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 10ms/step - loss: 2.1983 - accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, test_data['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 637ms/step\n",
      "[[0.00366104]\n",
      " [0.00494519]]\n"
     ]
    }
   ],
   "source": [
    "# when no plaraphrase detection  \n",
    "new_text = [\"How do I file for bankruptcy?\", \"Can you file for bankruptcy twice?\"]\n",
    "new_text = tokenizer.texts_to_sequences(new_text)\n",
    "new_text = pad_sequences(new_text, maxlen=100)\n",
    "prediction = model.predict(new_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into traing and test data \n",
    "train_data,test_data,train_labels,test_labels=train_test_split(data['Sentence1'].astype(str)+' '+data['Sentence2'].astype(str),data['Class'],\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the text data \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "test_vectors = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Logistric Regression model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lebales=model.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy 0.5221875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(pred_lebales,test_labels)\n",
    "print('Model Accuracy',accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Naive Bayes Classifier \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(train_vectors,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5078125\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy of the classifier \n",
    "accuracy=accuracy_score(y_pred,test_labels)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>But instead of returning to heaven , Annie dec...</td>\n",
       "      <td>But instead of returning to Heaven , Chris cho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In 2016 , Bacardi announced new branding and p...</td>\n",
       "      <td>In 2016 , Bacardi announced new branding and p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kweku Baako Jnr had four children . One of the...</td>\n",
       "      <td>Baako had four children , one of whom was Kwek...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As with the Navy , the Army has a single-track...</td>\n",
       "      <td>Like the army , the Navy has a single-track sy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sissi units have fewer crew served weapons and...</td>\n",
       "      <td>Sissi units have more weapons served by the cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          Sentence1  \\\n",
       "0   0  But instead of returning to heaven , Annie dec...   \n",
       "1   1  In 2016 , Bacardi announced new branding and p...   \n",
       "2   2  Kweku Baako Jnr had four children . One of the...   \n",
       "3   3  As with the Navy , the Army has a single-track...   \n",
       "4   4  Sissi units have fewer crew served weapons and...   \n",
       "\n",
       "                                           Sentence2  Class  \n",
       "0  But instead of returning to Heaven , Chris cho...      0  \n",
       "1  In 2016 , Bacardi announced new branding and p...      0  \n",
       "2  Baako had four children , one of whom was Kwek...      0  \n",
       "3  Like the army , the Navy has a single-track sy...      0  \n",
       "4  Sissi units have more weapons served by the cr...      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new=pd.read_csv('train1.csv')\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Length: 12800\n",
      "Testing Set Length: 3200\n",
      "training_sentences shape: (12800,)\n",
      "testing_sentences shape: (3200,)\n",
      "train_labels shape: (12800, 2)\n",
      "test_labels shape: (3200, 2)\n"
     ]
    }
   ],
   "source": [
    "train1, test1= train_test_split(data_new,random_state=42,test_size=0.2)\n",
    "training_sentences=[]\n",
    "testing_sentences=[]\n",
    "\n",
    "\n",
    "\n",
    "train_sentences=train1['Sentence1'].values\n",
    "train_labels=train1['Class'].values\n",
    "\n",
    "for i in range(train_sentences.shape[0]):\n",
    "    x=str(train_sentences[i])\n",
    "    training_sentences.append(x)\n",
    "training_sentences=np.array(training_sentences)\n",
    "\n",
    "\n",
    "\n",
    "test_sentences=test1['Sentence1'].values\n",
    "test_labels=test1['Class'].values\n",
    "\n",
    "for i in range(test_sentences.shape[0]):\n",
    "    x=str(test_sentences[i])\n",
    "    testing_sentences.append(x)\n",
    "\n",
    "testing_sentences=np.array(testing_sentences)\n",
    "\n",
    "train_labels=tf.keras.utils.to_categorical(train_labels)\n",
    "\n",
    "test_labels=tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "print(\"Training Set Length: \"+str(len(train1)))\n",
    "print(\"Testing Set Length: \"+str(len(test1)))\n",
    "print(\"training_sentences shape: \"+str(training_sentences.shape))\n",
    "print(\"testing_sentences shape: \"+str(testing_sentences.shape))\n",
    "print(\"train_labels shape: \"+str(train_labels.shape))\n",
    "print(\"test_labels shape: \"+str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tknzr=TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "\n",
    "def stem(doc):\n",
    "    return(stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "en_stopwords=list(STOP_WORDS)\n",
    "\n",
    "vectorizer=CountVectorizer(analyzer='word',\n",
    "                           tokenizer=tokenize,\n",
    "                           lowercase=True,\n",
    "                           ngram_range=(1,1),stop_words=en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kflod=StratifiedKFold(n_splits=5, shuffle=True,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "Pipeline_svm=make_pipeline(vectorizer,SVC(probability=True,kernel='linear',class_weight='balanced'))\n",
    "grid_svm=GridSearchCV(Pipeline_svm,\n",
    "                      param_grid={'svc__C':[0.01, 0.1,1]},\n",
    "                      cv=kflod,\n",
    "                      scoring='roc_auc',\n",
    "                      verbose=1,\n",
    "                      n_jobs=-1)\n",
    "train_labels_new=train1['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\env_python3.9\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                                        CountVectorizer(stop_words=[&#x27;wessen&#x27;,\n",
       "                                                                    &#x27;grosser&#x27;,\n",
       "                                                                    &#x27;ausser&#x27;,\n",
       "                                                                    &#x27;demgemÃ¤ÃŸ&#x27;,\n",
       "                                                                    &#x27;wahr&#x27;,\n",
       "                                                                    &#x27;tagen&#x27;,\n",
       "                                                                    &#x27;grosse&#x27;,\n",
       "                                                                    &#x27;wÃ¤hrenddem&#x27;,\n",
       "                                                                    &#x27;war&#x27;, &#x27;a&#x27;,\n",
       "                                                                    &#x27;ab&#x27;,\n",
       "                                                                    &#x27;entweder&#x27;,\n",
       "                                                                    &#x27;damit&#x27;,\n",
       "                                                                    &#x27;durchaus&#x27;,\n",
       "                                                                    &#x27;zehnter&#x27;,\n",
       "                                                                    &#x27;was&#x27;,\n",
       "                                                                    &#x27;richtig&#x27;,\n",
       "                                                                    &#x27;an&#x27;, &#x27;wen&#x27;,\n",
       "                                                                    &#x27;wegen&#x27;,\n",
       "                                                                    &#x27;rechter&#x27;,\n",
       "                                                                    &#x27;acht&#x27;,\n",
       "                                                                    &#x27;einen&#x27;,\n",
       "                                                                    &#x27;fÃ¼nf&#x27;,\n",
       "                                                                    &#x27;darf&#x27;,\n",
       "                                                                    &#x27;besten&#x27;,\n",
       "                                                                    &#x27;guter&#x27;,\n",
       "                                                                    &#x27;jedermann&#x27;,\n",
       "                                                                    &#x27;muss&#x27;,\n",
       "                                                                    &#x27;schon&#x27;, ...],\n",
       "                                                        tokenizer=&lt;function tokenize at 0x00000208BF00F3A0&gt;)),\n",
       "                                       (&#x27;svc&#x27;,\n",
       "                                        SVC(class_weight=&#x27;balanced&#x27;,\n",
       "                                            kernel=&#x27;linear&#x27;,\n",
       "                                            probability=True))]),\n",
       "             n_jobs=-1, param_grid={&#x27;svc__C&#x27;: [0.01, 0.1, 1]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                                        CountVectorizer(stop_words=[&#x27;wessen&#x27;,\n",
       "                                                                    &#x27;grosser&#x27;,\n",
       "                                                                    &#x27;ausser&#x27;,\n",
       "                                                                    &#x27;demgemÃ¤ÃŸ&#x27;,\n",
       "                                                                    &#x27;wahr&#x27;,\n",
       "                                                                    &#x27;tagen&#x27;,\n",
       "                                                                    &#x27;grosse&#x27;,\n",
       "                                                                    &#x27;wÃ¤hrenddem&#x27;,\n",
       "                                                                    &#x27;war&#x27;, &#x27;a&#x27;,\n",
       "                                                                    &#x27;ab&#x27;,\n",
       "                                                                    &#x27;entweder&#x27;,\n",
       "                                                                    &#x27;damit&#x27;,\n",
       "                                                                    &#x27;durchaus&#x27;,\n",
       "                                                                    &#x27;zehnter&#x27;,\n",
       "                                                                    &#x27;was&#x27;,\n",
       "                                                                    &#x27;richtig&#x27;,\n",
       "                                                                    &#x27;an&#x27;, &#x27;wen&#x27;,\n",
       "                                                                    &#x27;wegen&#x27;,\n",
       "                                                                    &#x27;rechter&#x27;,\n",
       "                                                                    &#x27;acht&#x27;,\n",
       "                                                                    &#x27;einen&#x27;,\n",
       "                                                                    &#x27;fÃ¼nf&#x27;,\n",
       "                                                                    &#x27;darf&#x27;,\n",
       "                                                                    &#x27;besten&#x27;,\n",
       "                                                                    &#x27;guter&#x27;,\n",
       "                                                                    &#x27;jedermann&#x27;,\n",
       "                                                                    &#x27;muss&#x27;,\n",
       "                                                                    &#x27;schon&#x27;, ...],\n",
       "                                                        tokenizer=&lt;function tokenize at 0x00000208BF00F3A0&gt;)),\n",
       "                                       (&#x27;svc&#x27;,\n",
       "                                        SVC(class_weight=&#x27;balanced&#x27;,\n",
       "                                            kernel=&#x27;linear&#x27;,\n",
       "                                            probability=True))]),\n",
       "             n_jobs=-1, param_grid={&#x27;svc__C&#x27;: [0.01, 0.1, 1]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                 CountVectorizer(stop_words=[&#x27;wessen&#x27;, &#x27;grosser&#x27;, &#x27;ausser&#x27;,\n",
       "                                             &#x27;demgemÃ¤ÃŸ&#x27;, &#x27;wahr&#x27;, &#x27;tagen&#x27;,\n",
       "                                             &#x27;grosse&#x27;, &#x27;wÃ¤hrenddem&#x27;, &#x27;war&#x27;, &#x27;a&#x27;,\n",
       "                                             &#x27;ab&#x27;, &#x27;entweder&#x27;, &#x27;damit&#x27;,\n",
       "                                             &#x27;durchaus&#x27;, &#x27;zehnter&#x27;, &#x27;was&#x27;,\n",
       "                                             &#x27;richtig&#x27;, &#x27;an&#x27;, &#x27;wen&#x27;, &#x27;wegen&#x27;,\n",
       "                                             &#x27;rechter&#x27;, &#x27;acht&#x27;, &#x27;einen&#x27;, &#x27;fÃ¼nf&#x27;,\n",
       "                                             &#x27;darf&#x27;, &#x27;besten&#x27;, &#x27;guter&#x27;,\n",
       "                                             &#x27;jedermann&#x27;, &#x27;muss&#x27;, &#x27;schon&#x27;, ...],\n",
       "                                 tokenizer=&lt;function tokenize at 0x00000208BF00F3A0&gt;)),\n",
       "                (&#x27;svc&#x27;,\n",
       "                 SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;,\n",
       "                     probability=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=[&#x27;wessen&#x27;, &#x27;grosser&#x27;, &#x27;ausser&#x27;, &#x27;demgemÃ¤ÃŸ&#x27;, &#x27;wahr&#x27;,\n",
       "                            &#x27;tagen&#x27;, &#x27;grosse&#x27;, &#x27;wÃ¤hrenddem&#x27;, &#x27;war&#x27;, &#x27;a&#x27;, &#x27;ab&#x27;,\n",
       "                            &#x27;entweder&#x27;, &#x27;damit&#x27;, &#x27;durchaus&#x27;, &#x27;zehnter&#x27;, &#x27;was&#x27;,\n",
       "                            &#x27;richtig&#x27;, &#x27;an&#x27;, &#x27;wen&#x27;, &#x27;wegen&#x27;, &#x27;rechter&#x27;, &#x27;acht&#x27;,\n",
       "                            &#x27;einen&#x27;, &#x27;fÃ¼nf&#x27;, &#x27;darf&#x27;, &#x27;besten&#x27;, &#x27;guter&#x27;,\n",
       "                            &#x27;jedermann&#x27;, &#x27;muss&#x27;, &#x27;schon&#x27;, ...],\n",
       "                tokenizer=&lt;function tokenize at 0x00000208BF00F3A0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                        CountVectorizer(stop_words=['wessen',\n",
       "                                                                    'grosser',\n",
       "                                                                    'ausser',\n",
       "                                                                    'demgemÃ¤ÃŸ',\n",
       "                                                                    'wahr',\n",
       "                                                                    'tagen',\n",
       "                                                                    'grosse',\n",
       "                                                                    'wÃ¤hrenddem',\n",
       "                                                                    'war', 'a',\n",
       "                                                                    'ab',\n",
       "                                                                    'entweder',\n",
       "                                                                    'damit',\n",
       "                                                                    'durchaus',\n",
       "                                                                    'zehnter',\n",
       "                                                                    'was',\n",
       "                                                                    'richtig',\n",
       "                                                                    'an', 'wen',\n",
       "                                                                    'wegen',\n",
       "                                                                    'rechter',\n",
       "                                                                    'acht',\n",
       "                                                                    'einen',\n",
       "                                                                    'fÃ¼nf',\n",
       "                                                                    'darf',\n",
       "                                                                    'besten',\n",
       "                                                                    'guter',\n",
       "                                                                    'jedermann',\n",
       "                                                                    'muss',\n",
       "                                                                    'schon', ...],\n",
       "                                                        tokenizer=<function tokenize at 0x00000208BF00F3A0>)),\n",
       "                                       ('svc',\n",
       "                                        SVC(class_weight='balanced',\n",
       "                                            kernel='linear',\n",
       "                                            probability=True))]),\n",
       "             n_jobs=-1, param_grid={'svc__C': [0.01, 0.1, 1]},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.fit(training_sentences,train_labels_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5428456665153005"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=test1['Sentence1'].values\n",
    "y_test=test1['Class'].values\n",
    "grid_svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 0.01}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5554024854213496"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score,f1_score,roc_curve,auc,roc_auc_score,recall_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(model, X, y):\n",
    "    pred_proba = model.predict_proba(X)[:, 1]\n",
    "    pred = model.predict(X)        \n",
    "\n",
    "    auc = roc_auc_score(y, pred_proba)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    prec = precision_score(y, pred)\n",
    "    rec = recall_score(y, pred)\n",
    "    result = {'auc': auc, 'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.5429075531673352,\n",
       " 'f1': 0.49085467243099434,\n",
       " 'acc': 0.5215625,\n",
       " 'precision': 0.4733803720333547,\n",
       " 'recall': 0.5096685082872928}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_results(grid_svm.best_estimator_, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\user\\anaconda3\\envs\\env_python3.9\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\env_python3.9\\lib\\site-packages (from xgboost) (1.26.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\envs\\env_python3.9\\lib\\site-packages (from xgboost) (1.11.3)\n"
     ]
    }
   ],
   "source": [
    "# Applying Xgboost \n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, accuracy_score,confusion_matrix,mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores: {0}\\nMean:{1:.3f}\\nstd:{2:.3f}\".format(scores,np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>But instead of returning to heaven , Annie dec...</td>\n",
       "      <td>But instead of returning to Heaven , Chris cho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In 2016 , Bacardi announced new branding and p...</td>\n",
       "      <td>In 2016 , Bacardi announced new branding and p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kweku Baako Jnr had four children . One of the...</td>\n",
       "      <td>Baako had four children , one of whom was Kwek...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As with the Navy , the Army has a single-track...</td>\n",
       "      <td>Like the army , the Navy has a single-track sy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sissi units have fewer crew served weapons and...</td>\n",
       "      <td>Sissi units have more weapons served by the cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>15995</td>\n",
       "      <td>On July 21st , 1919 , the army was renamed int...</td>\n",
       "      <td>On July 21 , 1919 , the army was renamed the C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>15996</td>\n",
       "      <td>In 2012 , the championships were held in Dunak...</td>\n",
       "      <td>In 2012 , the championships were held in Italy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>15997</td>\n",
       "      <td>At least 3 inserts were printed , but none of ...</td>\n",
       "      <td>At least 3 supplements were printed , but none...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>15998</td>\n",
       "      <td>The builders of Waimate North were also Willia...</td>\n",
       "      <td>The builders of St. James were also William Wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>15999</td>\n",
       "      <td>It was destroyed and finally rebuilt during th...</td>\n",
       "      <td>It was destroyed and finally rebuilt during th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                          Sentence1  \\\n",
       "0          0  But instead of returning to heaven , Annie dec...   \n",
       "1          1  In 2016 , Bacardi announced new branding and p...   \n",
       "2          2  Kweku Baako Jnr had four children . One of the...   \n",
       "3          3  As with the Navy , the Army has a single-track...   \n",
       "4          4  Sissi units have fewer crew served weapons and...   \n",
       "...      ...                                                ...   \n",
       "15995  15995  On July 21st , 1919 , the army was renamed int...   \n",
       "15996  15996  In 2012 , the championships were held in Dunak...   \n",
       "15997  15997  At least 3 inserts were printed , but none of ...   \n",
       "15998  15998  The builders of Waimate North were also Willia...   \n",
       "15999  15999  It was destroyed and finally rebuilt during th...   \n",
       "\n",
       "                                               Sentence2  Class  \n",
       "0      But instead of returning to Heaven , Chris cho...      0  \n",
       "1      In 2016 , Bacardi announced new branding and p...      0  \n",
       "2      Baako had four children , one of whom was Kwek...      0  \n",
       "3      Like the army , the Navy has a single-track sy...      0  \n",
       "4      Sissi units have more weapons served by the cr...      0  \n",
       "...                                                  ...    ...  \n",
       "15995  On July 21 , 1919 , the army was renamed the C...      1  \n",
       "15996  In 2012 , the championships were held in Italy...      0  \n",
       "15997  At least 3 supplements were printed , but none...      1  \n",
       "15998  The builders of St. James were also William Wi...      0  \n",
       "15999  It was destroyed and finally rebuilt during th...      0  \n",
       "\n",
       "[16000 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xgb=pd.read_csv('train1.csv')\n",
    "data_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>But instead of returning to heaven  Annie deci...</td>\n",
       "      <td>But instead of returning to Heaven  Chris choo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In 2016  Bacardi announced new branding and pl...</td>\n",
       "      <td>In 2016  Bacardi announced new branding and pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kweku Baako Jnr had four children  One of them...</td>\n",
       "      <td>Baako had four children  one of whom was Kweku...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As with the Navy  the Army has a singletrack s...</td>\n",
       "      <td>Like the army  the Navy has a singletrack syst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sissi units have fewer crew served weapons and...</td>\n",
       "      <td>Sissi units have more weapons served by the cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          Sentence1  \\\n",
       "0   0  But instead of returning to heaven  Annie deci...   \n",
       "1   1  In 2016  Bacardi announced new branding and pl...   \n",
       "2   2  Kweku Baako Jnr had four children  One of them...   \n",
       "3   3  As with the Navy  the Army has a singletrack s...   \n",
       "4   4  Sissi units have fewer crew served weapons and...   \n",
       "\n",
       "                                           Sentence2  Class  \n",
       "0  But instead of returning to Heaven  Chris choo...      0  \n",
       "1  In 2016  Bacardi announced new branding and pl...      0  \n",
       "2  Baako had four children  one of whom was Kweku...      0  \n",
       "3  Like the army  the Navy has a singletrack syst...      0  \n",
       "4  Sissi units have more weapons served by the cr...      0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from string import punctuation\n",
    "def remove_punctuation(text):\n",
    "    no_punctuation=[words for words in text if words not in punctuation ]\n",
    "    words_wo_punct=''.join(no_punctuation)\n",
    "    return words_wo_punct\n",
    "data_xgb[\"Sentence1\"]=data_xgb[\"Sentence1\"].apply(lambda x:remove_punctuation(x))\n",
    "data_xgb[\"Sentence2\"]=data_xgb[\"Sentence2\"].apply(lambda x:remove_punctuation(x))\n",
    "data_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "text_clean=[]\n",
    "\n",
    "for i in range (len(data_xgb['Sentence1'])):\n",
    "    char_clean=[]\n",
    "    for char in str(data_xgb['Sentence1'][i]).split():\n",
    "        char=char.lower()\n",
    "        if char not in stopwords.words('english'):\n",
    "            char_clean.append(char)\n",
    "        else:\n",
    "            continue\n",
    "    char_clean=' '.join(char_clean)\n",
    "    text_clean.append(char_clean)\n",
    "data_xgb[\"Sentence1\"]=text_clean           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#punctuation \n",
    "punc=list(punctuation)\n",
    "text_clean = []\n",
    "for i in range(len(data_xgb.Sentence1)):\n",
    "    char_clean = []\n",
    "    for char in data_xgb['Sentence1'][i]:\n",
    "        char = char.lower()\n",
    "        if char not in punc:\n",
    "            char_clean.append(char)\n",
    "        else:\n",
    "            continue\n",
    "    char_clean = ''.join(char_clean)\n",
    "    text_clean.append(char_clean)\n",
    "    \n",
    "data_xgb['Sentence1'] = text_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016 bacardi announced new branding plans sell version havana club nationally burned florida bottled puerto rico'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xgb.Sentence1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_xgb.Sentence1\n",
    "y=data_xgb.Class\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tunning \n",
    "from scipy.stats import uniform\n",
    "from scipy import interp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV,StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "param_dist={\"learning_rate\":uniform(0,2),\n",
    "            \"gamma\":uniform(1,0.000001),\n",
    "            \"max_depth\":range(1,50),\n",
    "            \"n_estimators\":range(1,300),\n",
    "            \"min_child_weight\":range(1,10),\n",
    "            'n_jobs':range(1,5)\n",
    "            }\n",
    "\n",
    "rs=RandomizedSearchCV(XGBClassifier(),param_distributions=param_dist,n_iter=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Pipeline([('count',CountVectorizer()),\n",
    "                ('tfidf',TfidfTransformer()),\n",
    "                ('model',rs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;count&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomizedSearchCV(estimator=XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature_types=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gro...\n",
       "                                                            random_state=None, ...),\n",
       "                                    n_iter=3,\n",
       "                                    param_distributions={&#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001DC6A5FF5B0&gt;,\n",
       "                                                         &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001DC5A519640&gt;,\n",
       "                                                         &#x27;max_depth&#x27;: range(1, 50),\n",
       "                                                         &#x27;min_child_weight&#x27;: range(1, 10),\n",
       "                                                         &#x27;n_estimators&#x27;: range(1, 300),\n",
       "                                                         &#x27;n_jobs&#x27;: range(1, 5)}))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;count&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomizedSearchCV(estimator=XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature_types=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gro...\n",
       "                                                            random_state=None, ...),\n",
       "                                    n_iter=3,\n",
       "                                    param_distributions={&#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001DC6A5FF5B0&gt;,\n",
       "                                                         &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001DC5A519640&gt;,\n",
       "                                                         &#x27;max_depth&#x27;: range(1, 50),\n",
       "                                                         &#x27;min_child_weight&#x27;: range(1, 10),\n",
       "                                                         &#x27;n_estimators&#x27;: range(1, 300),\n",
       "                                                         &#x27;n_jobs&#x27;: range(1, 5)}))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=3,\n",
       "                   param_distributions={&#x27;gamma&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001DC6A5FF5B0&gt;,\n",
       "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001DC5A519640&gt;,\n",
       "                                        &#x27;max_depth&#x27;: range(1, 50),\n",
       "                                        &#x27;min_child_weight&#x27;: range(1, 10),\n",
       "                                        &#x27;n_estimators&#x27;: range(1, 300),\n",
       "                                        &#x27;n_jobs&#x27;: range(1, 5)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('model',\n",
       "                 RandomizedSearchCV(estimator=XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            callbacks=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            device=None,\n",
       "                                                            early_stopping_rounds=None,\n",
       "                                                            enable_categorical=False,\n",
       "                                                            eval_metric=None,\n",
       "                                                            feature_types=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gro...\n",
       "                                                            random_state=None, ...),\n",
       "                                    n_iter=3,\n",
       "                                    param_distributions={'gamma': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001DC6A5FF5B0>,\n",
       "                                                         'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001DC5A519640>,\n",
       "                                                         'max_depth': range(1, 50),\n",
       "                                                         'min_child_weight': range(1, 10),\n",
       "                                                         'n_estimators': range(1, 300),\n",
       "                                                         'n_jobs': range(1, 5)}))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:  51.91 %\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy: ',round(accuracy_score(y_test, predictions)*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.61      1757\n",
      "           1       0.45      0.33      0.38      1443\n",
      "\n",
      "    accuracy                           0.52      3200\n",
      "   macro avg       0.50      0.50      0.49      3200\n",
      "weighted avg       0.51      0.52      0.51      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
